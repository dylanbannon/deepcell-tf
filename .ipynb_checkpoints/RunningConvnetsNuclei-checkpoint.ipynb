{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running conv-nets\n",
    "This ipython notebook walks you through the running_template.py script.\n",
    "\n",
    "First, we need to load the necessary python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Quadro K620 (CNMeM is disabled, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import tifffile as tiff\n",
    "from keras.backend.common import _UID_PREFIXES\n",
    "\n",
    "from cnn_functions import nikon_getfiles, get_image, run_models_on_directory, get_image_sizes, segment_nuclei, segment_cytoplasm, dice_jaccard_indices\n",
    "from model_zoo import sparse_bn_feature_net_61x61 as nuclear_fn\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imsave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to specify some directory locations - namely where the home data directory is (direc_name), where the raw images are located (data_location), where to store they cytoplasm prediction images (cyto_location), where to store the nuclear prediction images (nuclear_location), and where to store the final segmentation masks (mask_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc_name = './testing_data_allTogether/E2fNuclei/'\n",
    "data_location = os.path.join(direc_name, 'RawImages')\n",
    "\n",
    "nuclear_location = os.path.join(direc_name, 'Nuclear')\n",
    "mask_location = os.path.join(direc_name, 'Masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define the channel names. In this case, the cytoplasm network takes in phase and nuclear marker (far red) images. The channel names have to be present in the file names. We also need to specify the directory the conv-net parameter files live in and what the file names are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nuclear_channel_names = ['DAPI']\n",
    "\n",
    "trained_network_nuclear_directory = \"./trained_networks/E2fNuclei/\"\n",
    "nuclear_prefix = \"2018-01-02_nuclei_all_61x61_bn_feature_net_61x61_\"\n",
    "\n",
    "#trained_network_nuclear_directory = \"./trained_networks/\"\n",
    "#nuclear_prefix = \"2016-07-12_nuclei_all_61x61_bn_feature_net_61x61_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we normalize test data and save it in NormalizedRawData folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using a network that takes in 61x61 images in this example. We need to manually feed in the window size (the number of pixels sampled around each pixels). We also need to specify the image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_nuclear = 30\n",
    "\n",
    "image_size_x, image_size_y = get_image_sizes(data_location, nuclear_channel_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to load the weights for the networks. Remember we make use of two networks - one for the cytoplasm and another for the nucleus. Because we use model parallelism, we have 5 networks for each segmentation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_nuclear_weights = []\n",
    "for j in xrange(1):\n",
    "\tnuclear_weights = os.path.join(trained_network_nuclear_directory,  nuclear_prefix + str(j) + \".h5\")\n",
    "\tlist_of_nuclear_weights += [nuclear_weights]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run all our networks on all the files in our directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1 of 5\n",
      "Processing image 2 of 5\n",
      "Processing image 3 of 5\n"
     ]
    }
   ],
   "source": [
    "nuclear_predictions = run_models_on_directory(data_location, nuclear_channel_names, nuclear_location, model_fn = nuclear_fn, \n",
    "\tlist_of_weights = list_of_nuclear_weights, image_size_x = image_size_x, image_size_y = image_size_y, \n",
    "\twin_x = win_nuclear, win_y = win_nuclear, split = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to refine the neural network predictions to create segmentation masks. The smoothing and num_iters parameters control the active contour refinement process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nuclear_masks = segment_nuclei(nuclear_predictions, mask_location = mask_location, threshold = 0.75, area_threshold = 100, solidity_threshold = 0.75, eccentricity_threshold = 0.95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
